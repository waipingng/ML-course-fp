{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ae74fd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f944f623",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../BX_data_process_construction/top_features_df.csv\")\n",
    "race_counts = df[\"Race ID\"].value_counts()\n",
    "valid_races = race_counts[race_counts == 16].index\n",
    "df_16 = df[df[\"Race ID\"].isin(valid_races)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8fc74918",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h4/994pp03n5kg8x_b610__2_lm0000gn/T/ipykernel_28597/1959456823.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_16[\"lgb_label\"] = 16 - df_16[\"Finish Position\"]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2. Feature columns and target label\n",
    "feat_cols = [\n",
    "    'Favorite_Rank', 'Age_Scale', 'Bracket Number', 'Top3_Rank',\n",
    "    'Speed (m/s)_Rank', 'Track_Distance', 'Weight_Rank'\n",
    "]\n",
    "df_16[\"lgb_label\"] = 16 - df_16[\"Finish Position\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a00eca9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h4/994pp03n5kg8x_b610__2_lm0000gn/T/ipykernel_28597/1141575001.py:4: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_16_train = df_16[df[\"Race ID\"].isin(train_races)].copy()\n",
      "/var/folders/h4/994pp03n5kg8x_b610__2_lm0000gn/T/ipykernel_28597/1141575001.py:5: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_16_test = df_16[df[\"Race ID\"].isin(test_races)].copy()\n"
     ]
    }
   ],
   "source": [
    "# 3. Split by race\n",
    "unique_races = df_16[\"Race ID\"].unique()\n",
    "train_races, test_races = train_test_split(unique_races, test_size=0.2, random_state=42)\n",
    "df_16_train = df_16[df[\"Race ID\"].isin(train_races)].copy()\n",
    "df_16_test = df_16[df[\"Race ID\"].isin(test_races)].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f03f07c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Prepare inputs\n",
    "X_train = df_16_train[feat_cols]\n",
    "y_train = df_16_train[\"lgb_label\"]\n",
    "group_train = df_16_train.groupby(\"Race ID\").size().tolist()\n",
    "\n",
    "X_test = df_16_test[feat_cols]\n",
    "y_test = df_16_test[\"Finish Position\"]\n",
    "group_test = df_16_test.groupby(\"Race ID\").size().tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fc42cd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Define param grid to try manually\n",
    "param_grid = [\n",
    "    {\"num_leaves\": 31, \"learning_rate\": 0.1, \"min_child_samples\": 20},\n",
    "    {\"num_leaves\": 63, \"learning_rate\": 0.05, \"min_child_samples\": 10},\n",
    "    {\"num_leaves\": 127, \"learning_rate\": 0.01, \"min_child_samples\": 5},\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8fabad58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000329 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 325\n",
      "[LightGBM] [Info] Number of data points in the train set: 12944, number of used features: 7\n",
      "Params: {'num_leaves': 31, 'learning_rate': 0.1, 'min_child_samples': 20}, Top-1 Accuracy: 0.2069\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000147 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 325\n",
      "[LightGBM] [Info] Number of data points in the train set: 12944, number of used features: 7\n",
      "Params: {'num_leaves': 63, 'learning_rate': 0.05, 'min_child_samples': 10}, Top-1 Accuracy: 0.1724\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000162 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 325\n",
      "[LightGBM] [Info] Number of data points in the train set: 12944, number of used features: 7\n",
      "Params: {'num_leaves': 127, 'learning_rate': 0.01, 'min_child_samples': 5}, Top-1 Accuracy: 0.1921\n"
     ]
    }
   ],
   "source": [
    "# 6. Manual tuning loop\n",
    "best_acc = 0\n",
    "best_params = None\n",
    "\n",
    "for params in param_grid:\n",
    "    model = lgb.LGBMRanker(\n",
    "        objective='lambdarank',\n",
    "        metric='ndcg',\n",
    "        random_state=42,\n",
    "        **params\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train, group=group_train)\n",
    "    df_16_test[\"score\"] = model.predict(X_test)\n",
    "    df_16_test[\"pred_rank\"] = df_16_test.groupby(\"Race ID\")[\"score\"].rank(ascending=False, method=\"first\")\n",
    "    \n",
    "    pred_top1 = df_16_test[df_16_test[\"pred_rank\"] == 1]\n",
    "    actual_top1 = df_16_test[df_16_test[\"Finish Position\"] == 1]\n",
    "    \n",
    "    merged = pred_top1[[\"Race ID\", \"Horse ID\"]].merge(\n",
    "        actual_top1[[\"Race ID\", \"Horse ID\"]],\n",
    "        on=\"Race ID\",\n",
    "        suffixes=(\"_pred\", \"_true\")\n",
    "    )\n",
    "    merged[\"correct\"] = (merged[\"Horse ID_pred\"] == merged[\"Horse ID_true\"]).astype(int)\n",
    "    acc = merged[\"correct\"].mean()\n",
    "    \n",
    "    print(f\"Params: {params}, Top-1 Accuracy: {acc:.4f}\")\n",
    "    \n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_params = params\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "daea471a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy: 0.2069\n"
     ]
    }
   ],
   "source": [
    "print(f\"Top-1 Accuracy: {best_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
