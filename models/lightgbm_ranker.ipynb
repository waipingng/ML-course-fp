{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae74fd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f944f623",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/cleaned_race_results_for_lightgbm.csv\")\n",
    "race_counts = df[\"race_id\"].value_counts()\n",
    "valid_races = race_counts[race_counts == 16].index\n",
    "df_16 = df[df[\"race_id\"].isin(valid_races)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fc74918",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2. Feature columns and target label\n",
    "selected_features = [\"total_weight\", \n",
    "                     \"speed_mps\", \n",
    "                     \"avg_speed_mps\", \n",
    "                     \"favorite\", \n",
    "                     \"bracket_number\", \n",
    "                     \"age\", \n",
    "                     \"top3\", \n",
    "                     \"track_distance\", \n",
    "                     \"weather_weather01\", \n",
    "                     \"weather_weather02\"\n",
    "                     ]\n",
    "df_16[\"lgb_label\"] = 16 - df_16[\"finish_position\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a00eca9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Split by race\n",
    "unique_races = df_16[\"race_id\"].unique()\n",
    "train_races, test_races = train_test_split(unique_races, test_size=0.2, random_state=42)\n",
    "df_16_train = df_16[df[\"race_id\"].isin(train_races)].copy()\n",
    "df_16_test = df_16[df[\"race_id\"].isin(test_races)].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f03f07c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Prepare inputs\n",
    "X_train = df_16_train[selected_features]\n",
    "y_train = df_16_train[\"lgb_label\"]\n",
    "group_train = df_16_train.groupby(\"race_id\").size().tolist()\n",
    "\n",
    "X_test = df_16_test[selected_features]\n",
    "y_test = df_16_test[\"finish_position\"]\n",
    "group_test = df_16_test.groupby(\"race_id\").size().tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc42cd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Define param grid to try manually\n",
    "param_grid = [\n",
    "    {\"num_leaves\": 31, \"learning_rate\": 0.1, \"min_child_samples\": 20},\n",
    "    {\"num_leaves\": 63, \"learning_rate\": 0.05, \"min_child_samples\": 10},\n",
    "    {\"num_leaves\": 127, \"learning_rate\": 0.01, \"min_child_samples\": 5},\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fabad58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000164 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 787\n",
      "[LightGBM] [Info] Number of data points in the train set: 13040, number of used features: 10\n",
      "Params: {'num_leaves': 31, 'learning_rate': 0.1, 'min_child_samples': 20}, Top-1 Accuracy: 0.3922\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000187 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 787\n",
      "[LightGBM] [Info] Number of data points in the train set: 13040, number of used features: 10\n",
      "Params: {'num_leaves': 63, 'learning_rate': 0.05, 'min_child_samples': 10}, Top-1 Accuracy: 0.4265\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000204 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 787\n",
      "[LightGBM] [Info] Number of data points in the train set: 13040, number of used features: 10\n",
      "Params: {'num_leaves': 127, 'learning_rate': 0.01, 'min_child_samples': 5}, Top-1 Accuracy: 0.4069\n"
     ]
    }
   ],
   "source": [
    "# 6. Manual tuning loop\n",
    "best_acc = 0\n",
    "best_params = None\n",
    "\n",
    "for params in param_grid:\n",
    "    model = lgb.LGBMRanker(\n",
    "        objective='lambdarank',\n",
    "        metric='ndcg',\n",
    "        random_state=42,\n",
    "        **params\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train, group=group_train)\n",
    "    df_16_test[\"score\"] = model.predict(X_test)\n",
    "    df_16_test[\"pred_rank\"] = df_16_test.groupby(\"race_id\")[\"score\"].rank(ascending=False, method=\"first\")\n",
    "    \n",
    "    pred_top1 = df_16_test[df_16_test[\"pred_rank\"] == 1]\n",
    "    actual_top1 = df_16_test[df_16_test[\"finish_position\"] == 1]\n",
    "    \n",
    "    merged = pred_top1[[\"race_id\", \"horse_id\"]].merge(\n",
    "        actual_top1[[\"race_id\", \"horse_id\"]],\n",
    "        on=\"race_id\",\n",
    "        suffixes=(\"_pred\", \"_true\")\n",
    "    )\n",
    "    merged[\"correct\"] = (merged[\"horse_id_pred\"] == merged[\"horse_id_true\"]).astype(int)\n",
    "    acc = merged[\"correct\"].mean()\n",
    "    \n",
    "    print(f\"Params: {params}, Top-1 Accuracy: {acc:.4f}\")\n",
    "    \n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_params = params\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "daea471a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy: 0.4265\n"
     ]
    }
   ],
   "source": [
    "print(f\"Top-1 Accuracy: {best_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
